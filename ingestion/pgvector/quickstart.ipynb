{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62840365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# import libraries\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "from langchain_community.vectorstores.pgvector import PGVector\n",
    "from pyprojroot import here\n",
    "from langchain_postgres import PGVector\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07766b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# connection\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "connection = \"postgresql+psycopg://qul:{BangMuchlis123!}@localhost:5432/test_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bd0ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# load document from data source\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "file_path = here(\"data/txt/The Project Gutenberg eBook of A Christmas Carol in Prose; Being a Ghost Story of Christmas.txt\")\n",
    "loader = TextLoader(str(file_path))\n",
    "\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"bge-m3:latest\")\n",
    "\n",
    "query = \"The Project Gutenberg eBook of A Christmas Carol in Prose; Being a Ghost Story of Christmas\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af778819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# create pgvectore store\n",
    "# --------------------------------------------------------------\n",
    "\"\"\"\n",
    "Donwload postgresql to run locally:\n",
    "https://www.postgresql.org/download/\n",
    "\n",
    "How to install the pgvector extension:\n",
    "https://github.com/pgvector/pgvector\n",
    "\n",
    "Fix common installation issues:\n",
    "https://github.com/pgvector/pgvector?tab=readme-ov-file#installation-notes\n",
    "\"\"\"\n",
    "\n",
    "collection_name = \"The Project Gutenberg eBook of A Christmas Carol in Prose\"\n",
    "\n",
    "# create store \n",
    "vector_store = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=collection_name,\n",
    "    connection=connection,\n",
    "    use_jsonb=True,\n",
    ")\n",
    "\n",
    "# load store\n",
    "pgvector_docsearch = PGVector(\n",
    "    connection=connection,\n",
    "    collection_name=collection_name ,\n",
    "    embeddings=embeddings,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63072cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I am the Ghost of Christmas Past.\"\n",
      "\n",
      "\"Long Past?\" inquired Scrooge: observant of its dwarfish\n",
      "stature.\n",
      "\n",
      "\"No. Your past.\"\n",
      "\n",
      "Perhaps, Scrooge could not have told anybody why, if\n",
      "anybody could have asked him; but he had a special desire\n",
      "to see the Spirit in his cap; and begged him to be covered.\n",
      "\n",
      "\"What!\" exclaimed the Ghost, \"would you so soon put out,\n",
      "with worldly hands, the light I give? Is it not enough\n",
      "that you are one of those whose passions made this cap, and\n",
      "force me through whole trains of years to wear it low upon\n",
      "my brow!\"\n",
      "\n",
      "Scrooge reverently disclaimed all intention to offend\n",
      "or any knowledge of having wilfully \"bonneted\" the Spirit at\n",
      "any period of his life. He then made bold to inquire what\n",
      "business brought him there.\n",
      "\n",
      "\"Your welfare!\" said the Ghost.\n",
      "\n",
      "Scrooge expressed himself much obliged, but could not\n",
      "help thinking that a night of unbroken rest would have been\n",
      "more conducive to that end. The Spirit must have heard\n",
      "him thinking, for it said immediately:\n",
      "\n",
      "\"Your reclamation, then. Take heed!\"\n",
      "\n",
      "It put out its strong hand as it spoke, and clasped him\n",
      "gently by the arm.\n",
      "\n",
      "\"Rise! and walk with me!\"\n",
      "\n",
      "It would have been in vain for Scrooge to plead that the\n",
      "weather and the hour were not adapted to pedestrian purposes;\n",
      "that bed was warm, and the thermometer a long way below\n",
      "freezing; that he was clad but lightly in his slippers,\n",
      "dressing-gown, and nightcap; and that he had a cold upon him at\n",
      "that time. The grasp, though gentle as a woman's hand,\n",
      "was not to be resisted. He rose: but finding that the Spirit\n",
      "made towards the window, clasped his robe in supplication.\n",
      "\n",
      "\"I am a mortal,\" Scrooge remonstrated, \"and liable to fall.\"\n",
      "\n",
      "\"Bear but a touch of my hand there,\" said the Spirit,\n",
      "laying it upon his heart, \"and you shall be upheld in more\n",
      "than this!\"\n",
      "\n",
      "The function took an average of 0.16 seconds to execute.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# query the index with pgvector \n",
    "# --------------------------------------------------------------\n",
    "def run_query_pgvector(docsearch, query):\n",
    "    docs = docsearch.similarity_search(query, k=4)\n",
    "    result = docs[0].page_content\n",
    "    return result\n",
    "\n",
    "\n",
    "def calculate_average_execution_time(func, *args, **kwargs):\n",
    "    total_execution_time = 0\n",
    "    num_runs = 10\n",
    "    for _ in range(num_runs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs) \n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        total_execution_time += execution_time\n",
    "    average_execution_time = round(total_execution_time / num_runs, 2)\n",
    "    print(result)\n",
    "    print(\n",
    "        f\"\\nThe function took an average of {average_execution_time} seconds to execute.\"\n",
    "    )\n",
    "    return\n",
    "\n",
    "calculate_average_execution_time(\n",
    "    run_query_pgvector, docsearch=pgvector_docsearch, query=query\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898848d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1105, which is longer than the specified 1000\n",
      "Created a chunk of size 1437, which is longer than the specified 1000\n",
      "Created a chunk of size 1871, which is longer than the specified 1000\n",
      "Created a chunk of size 1015, which is longer than the specified 1000\n",
      "Created a chunk of size 1006, which is longer than the specified 1000\n",
      "Created a chunk of size 1054, which is longer than the specified 1000\n",
      "Created a chunk of size 1432, which is longer than the specified 1000\n",
      "Created a chunk of size 1367, which is longer than the specified 1000\n",
      "Created a chunk of size 2178, which is longer than the specified 1000\n",
      "Created a chunk of size 1390, which is longer than the specified 1000\n",
      "Created a chunk of size 1502, which is longer than the specified 1000\n",
      "Created a chunk of size 1410, which is longer than the specified 1000\n",
      "Created a chunk of size 1741, which is longer than the specified 1000\n",
      "Created a chunk of size 1184, which is longer than the specified 1000\n",
      "Created a chunk of size 1045, which is longer than the specified 1000\n",
      "Created a chunk of size 1132, which is longer than the specified 1000\n",
      "Created a chunk of size 1674, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# add more collection to pgvector\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "file_path = here(\"data/txt/The Project Gutenberg eBook of Romeo and Juliet.txt\")\n",
    "loader = TextLoader(str(file_path))\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "new_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "\n",
    "collection_name_2 = \"The Project Gutenberg eBook of Romeo and Juliet\"\n",
    "\n",
    "vector_store = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=collection_name_2,\n",
    "    connection=connection,\n",
    "    use_jsonb=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ddc9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Koleksi berhasil dihapus dari database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104608/1059428325.py:3: LangChainPendingDeprecationWarning: Please use JSONB instead of JSON for metadata. This change will allow for more efficient querying that involves filtering based on metadata. Please note that filtering operators have been changed when using JSONB metadata to be prefixed with a $ sign to avoid name collisions with columns. If you're using an existing database, you will need to create a db migration for your metadata column to be JSONB and update your queries to use the new operators. \n",
      "  pgvector = PGVector(\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# delete collection\n",
    "# --------------------------------------------------------------\n",
    "pgvector = PGVector(\n",
    "    collection_name=collection_name,\n",
    "    connection_string=connection,\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "\n",
    "pgvector.delete_collection()\n",
    "print(\"✅ Koleksi berhasil dihapus dari database.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-fun-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
